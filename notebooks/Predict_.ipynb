{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow.keras as tf\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report,f1_score,accuracy_score,roc_auc_score,roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORT DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= pd.read_csv(\"../data/X_train.csv\") \n",
    "y = pd.read_csv(\"../data/Y_train.csv\")\n",
    "x_test = pd.read_csv(\"../data/X_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Outcome\n",
       "AD         303\n",
       "C           97\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_trial = pd.read_csv(\"../data/Y_train.csv\")\n",
    "y_trial.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.replace({'C':0,'AD':1}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size=0.25, shuffle= True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ae_reduce(x_train, x_valid):\n",
    "    n_input = len(x_train.columns)\n",
    "    # n_hidden = len(x_train.columns)\n",
    "    n_latent = 190\n",
    "    epoch = 200\n",
    "    lr = 1e-3\n",
    "    encoder = Sequential([\n",
    "        Dense(n_input, activation='selu', input_dim=n_input),\n",
    "        # Dense(n_hidden, activation='selu'),\n",
    "        Dense(n_latent, activation='selu')\n",
    "    ])\n",
    "    decoder = Sequential([\n",
    "        # Dense(n_hidden, activation='selu'),\n",
    "        Dense(n_input, activation='selu')\n",
    "    ])\n",
    "    stacked_ae = Sequential([encoder,decoder])\n",
    "    checkpoint_cb = tf.callbacks.ModelCheckpoint(\"my__model.h5\",save_best_only=True)\n",
    "    early_stopping_cb = tf.callbacks.EarlyStopping(patience=3,restore_best_weights=True)\n",
    "    stacked_ae.compile(optimizer = tf.optimizers.Adam(learning_rate = lr), loss = tf.losses.mean_squared_error, metrics='accuracy')\n",
    "    # history = stacked_ae.fit(x_train, x_train, epochs=epoch, validation_data=[X_test, X_test],callbacks=[checkpoint_cb, early_stopping_cb])\n",
    "    history = stacked_ae.fit(x_train, x_train, epochs=epoch, validation_data=[x_valid, x_valid], verbose=0)\n",
    "    train_encoded = encoder.predict(x_train)\n",
    "    full_encoded = stacked_ae.predict(x_train)\n",
    "    test_encoded = encoder.predict(x_valid)\n",
    "    # print('mse:',mean_squared_error(stacked_ae.predict(full_encoded), x_train))\n",
    "    train_encoded = pd.DataFrame(train_encoded)\n",
    "    test_encoded = pd.DataFrame(test_encoded)\n",
    "    train_encoded['train_status'] = 'train' \n",
    "    test_encoded['train_status'] = 'test'\n",
    "    df_ae = pd.concat([train_encoded, test_encoded], axis = 0)\n",
    "    return df_ae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "10/10 [==============================] - 4s 120ms/step - loss: 2.6556 - accuracy: 0.0033 - val_loss: 0.5566 - val_accuracy: 0.0900\n",
      "Epoch 2/200\n",
      "10/10 [==============================] - 0s 43ms/step - loss: 0.3810 - accuracy: 0.0967 - val_loss: 0.2711 - val_accuracy: 0.2300\n",
      "Epoch 3/200\n",
      "10/10 [==============================] - 0s 43ms/step - loss: 0.2265 - accuracy: 0.2500 - val_loss: 0.1770 - val_accuracy: 0.2300\n",
      "Epoch 4/200\n",
      "10/10 [==============================] - 0s 41ms/step - loss: 0.1657 - accuracy: 0.2067 - val_loss: 0.1562 - val_accuracy: 0.0900\n",
      "Epoch 5/200\n",
      "10/10 [==============================] - 0s 35ms/step - loss: 0.1488 - accuracy: 0.0800 - val_loss: 0.1385 - val_accuracy: 0.2100\n",
      "Epoch 6/200\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.1379 - accuracy: 0.2067 - val_loss: 0.1354 - val_accuracy: 0.2800\n",
      "Epoch 7/200\n",
      "10/10 [==============================] - 1s 56ms/step - loss: 0.1331 - accuracy: 0.2800 - val_loss: 0.1303 - val_accuracy: 0.2100\n",
      "Epoch 8/200\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.1296 - accuracy: 0.2000 - val_loss: 0.1278 - val_accuracy: 0.3000\n",
      "Epoch 9/200\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.1272 - accuracy: 0.2333 - val_loss: 0.1266 - val_accuracy: 0.3500\n",
      "Epoch 10/200\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.1254 - accuracy: 0.2933 - val_loss: 0.1269 - val_accuracy: 0.3400\n",
      "Epoch 11/200\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.1249 - accuracy: 0.2200 - val_loss: 0.1267 - val_accuracy: 0.1500\n",
      "Epoch 12/200\n",
      "10/10 [==============================] - 0s 45ms/step - loss: 0.1243 - accuracy: 0.2433 - val_loss: 0.1239 - val_accuracy: 0.3500\n",
      "Epoch 13/200\n",
      "10/10 [==============================] - 0s 33ms/step - loss: 0.1233 - accuracy: 0.2667 - val_loss: 0.1233 - val_accuracy: 0.2300\n",
      "Epoch 14/200\n",
      "10/10 [==============================] - 1s 87ms/step - loss: 0.1229 - accuracy: 0.2867 - val_loss: 0.1233 - val_accuracy: 0.3400\n",
      "Epoch 15/200\n",
      "10/10 [==============================] - 1s 69ms/step - loss: 0.1215 - accuracy: 0.3067 - val_loss: 0.1226 - val_accuracy: 0.3300\n",
      "Epoch 16/200\n",
      "10/10 [==============================] - 0s 47ms/step - loss: 0.1201 - accuracy: 0.2567 - val_loss: 0.1214 - val_accuracy: 0.2500\n",
      "Epoch 17/200\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 0.1191 - accuracy: 0.2967 - val_loss: 0.1220 - val_accuracy: 0.2800\n",
      "Epoch 18/200\n",
      "10/10 [==============================] - 0s 40ms/step - loss: 0.1187 - accuracy: 0.2933 - val_loss: 0.1237 - val_accuracy: 0.3600\n",
      "Epoch 19/200\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.1181 - accuracy: 0.3167 - val_loss: 0.1193 - val_accuracy: 0.2800\n",
      "Epoch 20/200\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.1165 - accuracy: 0.2867 - val_loss: 0.1190 - val_accuracy: 0.3200\n",
      "Epoch 21/200\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.1168 - accuracy: 0.3333 - val_loss: 0.1189 - val_accuracy: 0.3200\n",
      "Epoch 22/200\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.1161 - accuracy: 0.2833 - val_loss: 0.1198 - val_accuracy: 0.2600\n",
      "Epoch 23/200\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.1166 - accuracy: 0.2867 - val_loss: 0.1179 - val_accuracy: 0.3500\n",
      "Epoch 24/200\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.1146 - accuracy: 0.3067 - val_loss: 0.1169 - val_accuracy: 0.3300\n",
      "Epoch 25/200\n",
      "10/10 [==============================] - 0s 34ms/step - loss: 0.1136 - accuracy: 0.3200 - val_loss: 0.1167 - val_accuracy: 0.3500\n",
      "Epoch 26/200\n",
      "10/10 [==============================] - 0s 32ms/step - loss: 0.1126 - accuracy: 0.3233 - val_loss: 0.1162 - val_accuracy: 0.3400\n",
      "Epoch 27/200\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.1124 - accuracy: 0.3433 - val_loss: 0.1181 - val_accuracy: 0.3500\n",
      "Epoch 28/200\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.1122 - accuracy: 0.3100 - val_loss: 0.1167 - val_accuracy: 0.3500\n",
      "Epoch 29/200\n",
      "10/10 [==============================] - 0s 34ms/step - loss: 0.1117 - accuracy: 0.3433 - val_loss: 0.1150 - val_accuracy: 0.3700\n",
      "Epoch 30/200\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.1109 - accuracy: 0.3533 - val_loss: 0.1147 - val_accuracy: 0.3200\n",
      "Epoch 31/200\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.1103 - accuracy: 0.3200 - val_loss: 0.1152 - val_accuracy: 0.3200\n",
      "Epoch 32/200\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.1101 - accuracy: 0.3233 - val_loss: 0.1144 - val_accuracy: 0.2600\n",
      "Epoch 33/200\n",
      "10/10 [==============================] - 1s 64ms/step - loss: 0.1093 - accuracy: 0.3233 - val_loss: 0.1143 - val_accuracy: 0.3000\n",
      "Epoch 34/200\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.1086 - accuracy: 0.3300 - val_loss: 0.1132 - val_accuracy: 0.2500\n",
      "Epoch 35/200\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.1081 - accuracy: 0.3400 - val_loss: 0.1139 - val_accuracy: 0.3700\n",
      "Epoch 36/200\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.1084 - accuracy: 0.3300 - val_loss: 0.1139 - val_accuracy: 0.3400\n",
      "Epoch 37/200\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.1075 - accuracy: 0.3667 - val_loss: 0.1113 - val_accuracy: 0.3100\n",
      "Epoch 38/200\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.1062 - accuracy: 0.3700 - val_loss: 0.1122 - val_accuracy: 0.2400\n",
      "Epoch 39/200\n",
      "10/10 [==============================] - 0s 40ms/step - loss: 0.1058 - accuracy: 0.3633 - val_loss: 0.1114 - val_accuracy: 0.3500\n",
      "Epoch 40/200\n",
      "10/10 [==============================] - 1s 63ms/step - loss: 0.1052 - accuracy: 0.3733 - val_loss: 0.1125 - val_accuracy: 0.3700\n",
      "Epoch 41/200\n",
      "10/10 [==============================] - 0s 50ms/step - loss: 0.1049 - accuracy: 0.3600 - val_loss: 0.1097 - val_accuracy: 0.3800\n",
      "Epoch 42/200\n",
      "10/10 [==============================] - 0s 51ms/step - loss: 0.1038 - accuracy: 0.3867 - val_loss: 0.1099 - val_accuracy: 0.3100\n",
      "Epoch 43/200\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1035 - accuracy: 0.3667 - val_loss: 0.1093 - val_accuracy: 0.3400\n",
      "Epoch 44/200\n",
      "10/10 [==============================] - 0s 39ms/step - loss: 0.1033 - accuracy: 0.3700 - val_loss: 0.1090 - val_accuracy: 0.3500\n",
      "Epoch 45/200\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.1030 - accuracy: 0.3867 - val_loss: 0.1088 - val_accuracy: 0.3800\n",
      "Epoch 46/200\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.1025 - accuracy: 0.3733 - val_loss: 0.1084 - val_accuracy: 0.2600\n",
      "Epoch 47/200\n",
      "10/10 [==============================] - 0s 35ms/step - loss: 0.1018 - accuracy: 0.3567 - val_loss: 0.1099 - val_accuracy: 0.3700\n",
      "Epoch 48/200\n",
      "10/10 [==============================] - 0s 40ms/step - loss: 0.1012 - accuracy: 0.3833 - val_loss: 0.1087 - val_accuracy: 0.3900\n",
      "Epoch 49/200\n",
      "10/10 [==============================] - 0s 32ms/step - loss: 0.1010 - accuracy: 0.3800 - val_loss: 0.1084 - val_accuracy: 0.3600\n",
      "Epoch 50/200\n",
      "10/10 [==============================] - 0s 34ms/step - loss: 0.1000 - accuracy: 0.3833 - val_loss: 0.1064 - val_accuracy: 0.3800\n",
      "Epoch 51/200\n",
      "10/10 [==============================] - 0s 38ms/step - loss: 0.0996 - accuracy: 0.3900 - val_loss: 0.1059 - val_accuracy: 0.3400\n",
      "Epoch 52/200\n",
      "10/10 [==============================] - 0s 44ms/step - loss: 0.0983 - accuracy: 0.4200 - val_loss: 0.1049 - val_accuracy: 0.2700\n",
      "Epoch 53/200\n",
      "10/10 [==============================] - 0s 35ms/step - loss: 0.0973 - accuracy: 0.3700 - val_loss: 0.1051 - val_accuracy: 0.3700\n",
      "Epoch 54/200\n",
      "10/10 [==============================] - 0s 41ms/step - loss: 0.0971 - accuracy: 0.4167 - val_loss: 0.1055 - val_accuracy: 0.3700\n",
      "Epoch 55/200\n",
      "10/10 [==============================] - 0s 39ms/step - loss: 0.0970 - accuracy: 0.4067 - val_loss: 0.1041 - val_accuracy: 0.3600\n",
      "Epoch 56/200\n",
      "10/10 [==============================] - 0s 39ms/step - loss: 0.0961 - accuracy: 0.3933 - val_loss: 0.1049 - val_accuracy: 0.3500\n",
      "Epoch 57/200\n",
      "10/10 [==============================] - 0s 32ms/step - loss: 0.0953 - accuracy: 0.3967 - val_loss: 0.1030 - val_accuracy: 0.3600\n",
      "Epoch 58/200\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0947 - accuracy: 0.3833 - val_loss: 0.1036 - val_accuracy: 0.3800\n",
      "Epoch 59/200\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0941 - accuracy: 0.4133 - val_loss: 0.1028 - val_accuracy: 0.3500\n",
      "Epoch 60/200\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0935 - accuracy: 0.4067 - val_loss: 0.1034 - val_accuracy: 0.3700\n",
      "Epoch 61/200\n",
      "10/10 [==============================] - 0s 31ms/step - loss: 0.0933 - accuracy: 0.3867 - val_loss: 0.1022 - val_accuracy: 0.3700\n",
      "Epoch 62/200\n",
      "10/10 [==============================] - 0s 32ms/step - loss: 0.0927 - accuracy: 0.4033 - val_loss: 0.1021 - val_accuracy: 0.3500\n",
      "Epoch 63/200\n",
      "10/10 [==============================] - 0s 35ms/step - loss: 0.0920 - accuracy: 0.4200 - val_loss: 0.1007 - val_accuracy: 0.3300\n",
      "Epoch 64/200\n",
      "10/10 [==============================] - 0s 42ms/step - loss: 0.0910 - accuracy: 0.4033 - val_loss: 0.1008 - val_accuracy: 0.3300\n",
      "Epoch 65/200\n",
      "10/10 [==============================] - 0s 35ms/step - loss: 0.0905 - accuracy: 0.4033 - val_loss: 0.1011 - val_accuracy: 0.3300\n",
      "Epoch 66/200\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0905 - accuracy: 0.4067 - val_loss: 0.0996 - val_accuracy: 0.3400\n",
      "Epoch 67/200\n",
      "10/10 [==============================] - 0s 50ms/step - loss: 0.0898 - accuracy: 0.3833 - val_loss: 0.1001 - val_accuracy: 0.3500\n",
      "Epoch 68/200\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.0897 - accuracy: 0.4233 - val_loss: 0.1010 - val_accuracy: 0.3800\n",
      "Epoch 69/200\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0884 - accuracy: 0.4167 - val_loss: 0.0998 - val_accuracy: 0.3600\n",
      "Epoch 70/200\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0885 - accuracy: 0.4267 - val_loss: 0.0994 - val_accuracy: 0.3600\n",
      "Epoch 71/200\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0878 - accuracy: 0.4167 - val_loss: 0.0986 - val_accuracy: 0.4000\n",
      "Epoch 72/200\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0872 - accuracy: 0.4233 - val_loss: 0.0988 - val_accuracy: 0.4000\n",
      "Epoch 73/200\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0864 - accuracy: 0.4033 - val_loss: 0.0993 - val_accuracy: 0.3400\n",
      "Epoch 74/200\n",
      "10/10 [==============================] - 0s 34ms/step - loss: 0.0862 - accuracy: 0.4033 - val_loss: 0.0967 - val_accuracy: 0.3600\n",
      "Epoch 75/200\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0847 - accuracy: 0.4433 - val_loss: 0.0976 - val_accuracy: 0.3600\n",
      "Epoch 76/200\n",
      "10/10 [==============================] - 0s 33ms/step - loss: 0.0844 - accuracy: 0.4267 - val_loss: 0.0966 - val_accuracy: 0.3300\n",
      "Epoch 77/200\n",
      "10/10 [==============================] - 0s 31ms/step - loss: 0.0832 - accuracy: 0.4467 - val_loss: 0.0953 - val_accuracy: 0.3400\n",
      "Epoch 78/200\n",
      "10/10 [==============================] - 0s 38ms/step - loss: 0.0827 - accuracy: 0.4567 - val_loss: 0.0954 - val_accuracy: 0.3600\n",
      "Epoch 79/200\n",
      "10/10 [==============================] - 0s 32ms/step - loss: 0.0823 - accuracy: 0.4200 - val_loss: 0.0960 - val_accuracy: 0.3200\n",
      "Epoch 80/200\n",
      "10/10 [==============================] - 0s 39ms/step - loss: 0.0820 - accuracy: 0.4200 - val_loss: 0.0946 - val_accuracy: 0.3800\n",
      "Epoch 81/200\n",
      "10/10 [==============================] - 0s 35ms/step - loss: 0.0814 - accuracy: 0.4433 - val_loss: 0.0933 - val_accuracy: 0.3700\n",
      "Epoch 82/200\n",
      "10/10 [==============================] - 0s 34ms/step - loss: 0.0802 - accuracy: 0.4400 - val_loss: 0.0938 - val_accuracy: 0.3600\n",
      "Epoch 83/200\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.0798 - accuracy: 0.4533 - val_loss: 0.0938 - val_accuracy: 0.3500\n",
      "Epoch 84/200\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0795 - accuracy: 0.4567 - val_loss: 0.0933 - val_accuracy: 0.3800\n",
      "Epoch 85/200\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0789 - accuracy: 0.4433 - val_loss: 0.0928 - val_accuracy: 0.3500\n",
      "Epoch 86/200\n",
      "10/10 [==============================] - 0s 35ms/step - loss: 0.0779 - accuracy: 0.4433 - val_loss: 0.0928 - val_accuracy: 0.3100\n",
      "Epoch 87/200\n",
      "10/10 [==============================] - 0s 32ms/step - loss: 0.0777 - accuracy: 0.4400 - val_loss: 0.0925 - val_accuracy: 0.3800\n",
      "Epoch 88/200\n",
      "10/10 [==============================] - 0s 39ms/step - loss: 0.0774 - accuracy: 0.4200 - val_loss: 0.0907 - val_accuracy: 0.3500\n",
      "Epoch 89/200\n",
      "10/10 [==============================] - 0s 47ms/step - loss: 0.0761 - accuracy: 0.4400 - val_loss: 0.0905 - val_accuracy: 0.3800\n",
      "Epoch 90/200\n",
      "10/10 [==============================] - 0s 46ms/step - loss: 0.0755 - accuracy: 0.4233 - val_loss: 0.0911 - val_accuracy: 0.3200\n",
      "Epoch 91/200\n",
      "10/10 [==============================] - 0s 32ms/step - loss: 0.0750 - accuracy: 0.4667 - val_loss: 0.0892 - val_accuracy: 0.3500\n",
      "Epoch 92/200\n",
      "10/10 [==============================] - 0s 38ms/step - loss: 0.0740 - accuracy: 0.4733 - val_loss: 0.0893 - val_accuracy: 0.4100\n",
      "Epoch 93/200\n",
      "10/10 [==============================] - 0s 38ms/step - loss: 0.0737 - accuracy: 0.4367 - val_loss: 0.0910 - val_accuracy: 0.3800\n",
      "Epoch 94/200\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0733 - accuracy: 0.4467 - val_loss: 0.0887 - val_accuracy: 0.4000\n",
      "Epoch 95/200\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.0719 - accuracy: 0.4833 - val_loss: 0.0892 - val_accuracy: 0.3600\n",
      "Epoch 96/200\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0726 - accuracy: 0.4633 - val_loss: 0.0886 - val_accuracy: 0.4000\n",
      "Epoch 97/200\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0724 - accuracy: 0.4567 - val_loss: 0.0895 - val_accuracy: 0.3900\n",
      "Epoch 98/200\n",
      "10/10 [==============================] - 0s 38ms/step - loss: 0.0722 - accuracy: 0.4400 - val_loss: 0.0893 - val_accuracy: 0.4000\n",
      "Epoch 99/200\n",
      "10/10 [==============================] - 0s 36ms/step - loss: 0.0710 - accuracy: 0.4433 - val_loss: 0.0884 - val_accuracy: 0.3800\n",
      "Epoch 100/200\n",
      "10/10 [==============================] - 0s 41ms/step - loss: 0.0710 - accuracy: 0.4467 - val_loss: 0.0883 - val_accuracy: 0.3900\n",
      "Epoch 101/200\n",
      "10/10 [==============================] - 0s 41ms/step - loss: 0.0701 - accuracy: 0.4600 - val_loss: 0.0876 - val_accuracy: 0.3400\n",
      "Epoch 102/200\n",
      "10/10 [==============================] - 0s 46ms/step - loss: 0.0693 - accuracy: 0.4433 - val_loss: 0.0865 - val_accuracy: 0.4000\n",
      "Epoch 103/200\n",
      "10/10 [==============================] - 0s 44ms/step - loss: 0.0683 - accuracy: 0.4400 - val_loss: 0.0862 - val_accuracy: 0.3900\n",
      "Epoch 104/200\n",
      "10/10 [==============================] - 0s 39ms/step - loss: 0.0678 - accuracy: 0.4500 - val_loss: 0.0855 - val_accuracy: 0.4100\n",
      "Epoch 105/200\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0675 - accuracy: 0.4467 - val_loss: 0.0848 - val_accuracy: 0.4100\n",
      "Epoch 106/200\n",
      "10/10 [==============================] - 0s 31ms/step - loss: 0.0669 - accuracy: 0.4567 - val_loss: 0.0855 - val_accuracy: 0.3100\n",
      "Epoch 107/200\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0663 - accuracy: 0.4867 - val_loss: 0.0840 - val_accuracy: 0.3800\n",
      "Epoch 108/200\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0658 - accuracy: 0.4800 - val_loss: 0.0850 - val_accuracy: 0.4000\n",
      "Epoch 109/200\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0665 - accuracy: 0.4433 - val_loss: 0.0847 - val_accuracy: 0.4300\n",
      "Epoch 110/200\n",
      "10/10 [==============================] - 0s 34ms/step - loss: 0.0661 - accuracy: 0.4767 - val_loss: 0.0844 - val_accuracy: 0.3700\n",
      "Epoch 111/200\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0651 - accuracy: 0.4700 - val_loss: 0.0842 - val_accuracy: 0.4000\n",
      "Epoch 112/200\n",
      "10/10 [==============================] - 0s 31ms/step - loss: 0.0643 - accuracy: 0.4600 - val_loss: 0.0831 - val_accuracy: 0.3700\n",
      "Epoch 113/200\n",
      "10/10 [==============================] - 0s 43ms/step - loss: 0.0637 - accuracy: 0.4700 - val_loss: 0.0824 - val_accuracy: 0.3800\n",
      "Epoch 114/200\n",
      "10/10 [==============================] - 0s 34ms/step - loss: 0.0630 - accuracy: 0.4633 - val_loss: 0.0821 - val_accuracy: 0.3500\n",
      "Epoch 115/200\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0624 - accuracy: 0.4700 - val_loss: 0.0822 - val_accuracy: 0.3700\n",
      "Epoch 116/200\n",
      "10/10 [==============================] - 0s 39ms/step - loss: 0.0622 - accuracy: 0.4900 - val_loss: 0.0827 - val_accuracy: 0.3100\n",
      "Epoch 117/200\n",
      "10/10 [==============================] - 0s 39ms/step - loss: 0.0621 - accuracy: 0.4900 - val_loss: 0.0821 - val_accuracy: 0.3400\n",
      "Epoch 118/200\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0620 - accuracy: 0.4733 - val_loss: 0.0828 - val_accuracy: 0.3800\n",
      "Epoch 119/200\n",
      "10/10 [==============================] - 0s 40ms/step - loss: 0.0619 - accuracy: 0.4833 - val_loss: 0.0820 - val_accuracy: 0.3900\n",
      "Epoch 120/200\n",
      "10/10 [==============================] - 0s 31ms/step - loss: 0.0611 - accuracy: 0.4800 - val_loss: 0.0812 - val_accuracy: 0.4200\n",
      "Epoch 121/200\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0600 - accuracy: 0.4800 - val_loss: 0.0803 - val_accuracy: 0.4000\n",
      "Epoch 122/200\n",
      "10/10 [==============================] - 0s 35ms/step - loss: 0.0597 - accuracy: 0.4933 - val_loss: 0.0800 - val_accuracy: 0.3700\n",
      "Epoch 123/200\n",
      "10/10 [==============================] - 0s 47ms/step - loss: 0.0593 - accuracy: 0.4800 - val_loss: 0.0807 - val_accuracy: 0.3300\n",
      "Epoch 124/200\n",
      "10/10 [==============================] - 0s 50ms/step - loss: 0.0591 - accuracy: 0.4567 - val_loss: 0.0795 - val_accuracy: 0.4300\n",
      "Epoch 125/200\n",
      "10/10 [==============================] - 0s 46ms/step - loss: 0.0586 - accuracy: 0.4900 - val_loss: 0.0800 - val_accuracy: 0.3000\n",
      "Epoch 126/200\n",
      "10/10 [==============================] - 0s 42ms/step - loss: 0.0588 - accuracy: 0.5033 - val_loss: 0.0793 - val_accuracy: 0.3300\n",
      "Epoch 127/200\n",
      "10/10 [==============================] - 0s 41ms/step - loss: 0.0584 - accuracy: 0.4833 - val_loss: 0.0789 - val_accuracy: 0.4000\n",
      "Epoch 128/200\n",
      "10/10 [==============================] - 0s 34ms/step - loss: 0.0579 - accuracy: 0.4967 - val_loss: 0.0790 - val_accuracy: 0.4000\n",
      "Epoch 129/200\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0571 - accuracy: 0.5167 - val_loss: 0.0788 - val_accuracy: 0.3700\n",
      "Epoch 130/200\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.0566 - accuracy: 0.4767 - val_loss: 0.0791 - val_accuracy: 0.4000\n",
      "Epoch 131/200\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0566 - accuracy: 0.5000 - val_loss: 0.0776 - val_accuracy: 0.3300\n",
      "Epoch 132/200\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0560 - accuracy: 0.4767 - val_loss: 0.0777 - val_accuracy: 0.4000\n",
      "Epoch 133/200\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0556 - accuracy: 0.4767 - val_loss: 0.0779 - val_accuracy: 0.4200\n",
      "Epoch 134/200\n",
      "10/10 [==============================] - 0s 31ms/step - loss: 0.0556 - accuracy: 0.4900 - val_loss: 0.0773 - val_accuracy: 0.3900\n",
      "Epoch 135/200\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0554 - accuracy: 0.4867 - val_loss: 0.0776 - val_accuracy: 0.4300\n",
      "Epoch 136/200\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0547 - accuracy: 0.4967 - val_loss: 0.0765 - val_accuracy: 0.3900\n",
      "Epoch 137/200\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0544 - accuracy: 0.5033 - val_loss: 0.0770 - val_accuracy: 0.3900\n",
      "Epoch 138/200\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0544 - accuracy: 0.5100 - val_loss: 0.0789 - val_accuracy: 0.4200\n",
      "Epoch 139/200\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0549 - accuracy: 0.5067 - val_loss: 0.0783 - val_accuracy: 0.4300\n",
      "Epoch 140/200\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.0547 - accuracy: 0.4967 - val_loss: 0.0781 - val_accuracy: 0.4600\n",
      "Epoch 141/200\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0540 - accuracy: 0.5300 - val_loss: 0.0764 - val_accuracy: 0.4300\n",
      "Epoch 142/200\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0528 - accuracy: 0.4967 - val_loss: 0.0751 - val_accuracy: 0.4000\n",
      "Epoch 143/200\n",
      "10/10 [==============================] - 0s 32ms/step - loss: 0.0525 - accuracy: 0.5167 - val_loss: 0.0762 - val_accuracy: 0.3900\n",
      "Epoch 144/200\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0527 - accuracy: 0.5067 - val_loss: 0.0749 - val_accuracy: 0.3700\n",
      "Epoch 145/200\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0517 - accuracy: 0.5333 - val_loss: 0.0738 - val_accuracy: 0.4000\n",
      "Epoch 146/200\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0514 - accuracy: 0.4967 - val_loss: 0.0751 - val_accuracy: 0.4000\n",
      "Epoch 147/200\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.0515 - accuracy: 0.5033 - val_loss: 0.0746 - val_accuracy: 0.3500\n",
      "Epoch 148/200\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0506 - accuracy: 0.5467 - val_loss: 0.0742 - val_accuracy: 0.4500\n",
      "Epoch 149/200\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0504 - accuracy: 0.5267 - val_loss: 0.0725 - val_accuracy: 0.4100\n",
      "Epoch 150/200\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0496 - accuracy: 0.5200 - val_loss: 0.0729 - val_accuracy: 0.3500\n",
      "Epoch 151/200\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0493 - accuracy: 0.5333 - val_loss: 0.0730 - val_accuracy: 0.3800\n",
      "Epoch 152/200\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.0490 - accuracy: 0.5067 - val_loss: 0.0725 - val_accuracy: 0.4400\n",
      "Epoch 153/200\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0491 - accuracy: 0.5100 - val_loss: 0.0735 - val_accuracy: 0.4500\n",
      "Epoch 154/200\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.0493 - accuracy: 0.5300 - val_loss: 0.0728 - val_accuracy: 0.3600\n",
      "Epoch 155/200\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.0485 - accuracy: 0.5200 - val_loss: 0.0724 - val_accuracy: 0.3800\n",
      "Epoch 156/200\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0480 - accuracy: 0.5200 - val_loss: 0.0728 - val_accuracy: 0.3400\n",
      "Epoch 157/200\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0483 - accuracy: 0.5000 - val_loss: 0.0730 - val_accuracy: 0.4000\n",
      "Epoch 158/200\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0483 - accuracy: 0.5100 - val_loss: 0.0725 - val_accuracy: 0.3600\n",
      "Epoch 159/200\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0489 - accuracy: 0.5400 - val_loss: 0.0722 - val_accuracy: 0.3500\n",
      "Epoch 160/200\n",
      "10/10 [==============================] - 0s 32ms/step - loss: 0.0475 - accuracy: 0.5133 - val_loss: 0.0724 - val_accuracy: 0.3800\n",
      "Epoch 161/200\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0473 - accuracy: 0.5333 - val_loss: 0.0715 - val_accuracy: 0.4800\n",
      "Epoch 162/200\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.0462 - accuracy: 0.5367 - val_loss: 0.0704 - val_accuracy: 0.4400\n",
      "Epoch 163/200\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0465 - accuracy: 0.5400 - val_loss: 0.0708 - val_accuracy: 0.5000\n",
      "Epoch 164/200\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.0460 - accuracy: 0.5267 - val_loss: 0.0707 - val_accuracy: 0.4800\n",
      "Epoch 165/200\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.0458 - accuracy: 0.5200 - val_loss: 0.0706 - val_accuracy: 0.4300\n",
      "Epoch 166/200\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0454 - accuracy: 0.5467 - val_loss: 0.0700 - val_accuracy: 0.4400\n",
      "Epoch 167/200\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0451 - accuracy: 0.5400 - val_loss: 0.0704 - val_accuracy: 0.3900\n",
      "Epoch 168/200\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0452 - accuracy: 0.5633 - val_loss: 0.0709 - val_accuracy: 0.4100\n",
      "Epoch 169/200\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0451 - accuracy: 0.5200 - val_loss: 0.0700 - val_accuracy: 0.3700\n",
      "Epoch 170/200\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0447 - accuracy: 0.5367 - val_loss: 0.0695 - val_accuracy: 0.4300\n",
      "Epoch 171/200\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0442 - accuracy: 0.5633 - val_loss: 0.0695 - val_accuracy: 0.3600\n",
      "Epoch 172/200\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0442 - accuracy: 0.5167 - val_loss: 0.0693 - val_accuracy: 0.3700\n",
      "Epoch 173/200\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.0439 - accuracy: 0.5433 - val_loss: 0.0697 - val_accuracy: 0.4800\n",
      "Epoch 174/200\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0439 - accuracy: 0.5267 - val_loss: 0.0681 - val_accuracy: 0.4500\n",
      "Epoch 175/200\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0439 - accuracy: 0.5500 - val_loss: 0.0687 - val_accuracy: 0.3900\n",
      "Epoch 176/200\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0444 - accuracy: 0.5267 - val_loss: 0.0687 - val_accuracy: 0.4100\n",
      "Epoch 177/200\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.0431 - accuracy: 0.5433 - val_loss: 0.0686 - val_accuracy: 0.4200\n",
      "Epoch 178/200\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0430 - accuracy: 0.5500 - val_loss: 0.0694 - val_accuracy: 0.3900\n",
      "Epoch 179/200\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0432 - accuracy: 0.5467 - val_loss: 0.0684 - val_accuracy: 0.4800\n",
      "Epoch 180/200\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0421 - accuracy: 0.5500 - val_loss: 0.0681 - val_accuracy: 0.4000\n",
      "Epoch 181/200\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.0418 - accuracy: 0.5500 - val_loss: 0.0683 - val_accuracy: 0.3800\n",
      "Epoch 182/200\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.0419 - accuracy: 0.5567 - val_loss: 0.0667 - val_accuracy: 0.4200\n",
      "Epoch 183/200\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.0409 - accuracy: 0.5633 - val_loss: 0.0680 - val_accuracy: 0.4000\n",
      "Epoch 184/200\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.0413 - accuracy: 0.5567 - val_loss: 0.0680 - val_accuracy: 0.4200\n",
      "Epoch 185/200\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0423 - accuracy: 0.5533 - val_loss: 0.0676 - val_accuracy: 0.4400\n",
      "Epoch 186/200\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0415 - accuracy: 0.5667 - val_loss: 0.0663 - val_accuracy: 0.4500\n",
      "Epoch 187/200\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0407 - accuracy: 0.5733 - val_loss: 0.0672 - val_accuracy: 0.5100\n",
      "Epoch 188/200\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0410 - accuracy: 0.5533 - val_loss: 0.0658 - val_accuracy: 0.4900\n",
      "Epoch 189/200\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0404 - accuracy: 0.5833 - val_loss: 0.0668 - val_accuracy: 0.4500\n",
      "Epoch 190/200\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0403 - accuracy: 0.5633 - val_loss: 0.0662 - val_accuracy: 0.4500\n",
      "Epoch 191/200\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0395 - accuracy: 0.5500 - val_loss: 0.0663 - val_accuracy: 0.4400\n",
      "Epoch 192/200\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0399 - accuracy: 0.5867 - val_loss: 0.0656 - val_accuracy: 0.3800\n",
      "Epoch 193/200\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0392 - accuracy: 0.5733 - val_loss: 0.0662 - val_accuracy: 0.4100\n",
      "Epoch 194/200\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0390 - accuracy: 0.5733 - val_loss: 0.0651 - val_accuracy: 0.4200\n",
      "Epoch 195/200\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0388 - accuracy: 0.5767 - val_loss: 0.0653 - val_accuracy: 0.4300\n",
      "Epoch 196/200\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.0385 - accuracy: 0.5733 - val_loss: 0.0656 - val_accuracy: 0.4400\n",
      "Epoch 197/200\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0389 - accuracy: 0.5633 - val_loss: 0.0657 - val_accuracy: 0.4400\n",
      "Epoch 198/200\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0387 - accuracy: 0.5833 - val_loss: 0.0651 - val_accuracy: 0.4700\n",
      "Epoch 199/200\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0382 - accuracy: 0.5567 - val_loss: 0.0653 - val_accuracy: 0.4200\n",
      "Epoch 200/200\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.0383 - accuracy: 0.5667 - val_loss: 0.0636 - val_accuracy: 0.4600\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "10/10 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "df_ae = ae_reduce(x_train, x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train    300\n",
       "test     100\n",
       "Name: train_status, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ae['train_status'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=57)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Outcome\n",
       "0          0\n",
       "1          1\n",
       "2          0\n",
       "3          0\n",
       "4          1\n",
       "..       ...\n",
       "395        1\n",
       "396        1\n",
       "397        1\n",
       "398        1\n",
       "399        1\n",
       "\n",
       "[400 rows x 1 columns]"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_viz = pca.fit_transform(x)\n",
    "x_viz = pd.DataFrame(x_viz)\n",
    "y = pd.DataFrame(y)\n",
    "# x_viz_1 = pd.concat([x_viz,y], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Outcome\n",
       "1          303\n",
       "0           97\n",
       "dtype: int64"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_viz = pd.concat([x_viz,y], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_viz['Outcome'] = df_viz['Outcome'].replace({0:\"Control\",1:\"Disease\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: xlabel='0', ylabel='1'>"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# !pip install seaborn\n",
    "import seaborn as sns\n",
    "sns.scatterplot(data=df_viz, x=0, y=1, hue=\"Outcome\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pca_train = pca.fit_transform(x_train)\n",
    "x_pca_valid = pca.transform(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7077119103739355\n"
     ]
    }
   ],
   "source": [
    "print(sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nahomw\\AppData\\Local\\Temp\\ipykernel_27772\\1910710096.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_ae_x.drop(columns = ['train_status'], inplace = True)\n"
     ]
    }
   ],
   "source": [
    "train_ae_x = df_ae.loc[df_ae['train_status'] =='train']\n",
    "train_ae_x.drop(columns = ['train_status'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>180</th>\n",
       "      <th>181</th>\n",
       "      <th>182</th>\n",
       "      <th>183</th>\n",
       "      <th>184</th>\n",
       "      <th>185</th>\n",
       "      <th>186</th>\n",
       "      <th>187</th>\n",
       "      <th>188</th>\n",
       "      <th>189</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.286011</td>\n",
       "      <td>-1.681617</td>\n",
       "      <td>-1.607033</td>\n",
       "      <td>0.750308</td>\n",
       "      <td>-1.291434</td>\n",
       "      <td>1.755265</td>\n",
       "      <td>0.011078</td>\n",
       "      <td>-1.658436</td>\n",
       "      <td>-1.562615</td>\n",
       "      <td>-1.720451</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.557999</td>\n",
       "      <td>-1.172544</td>\n",
       "      <td>-0.967577</td>\n",
       "      <td>0.428967</td>\n",
       "      <td>0.268811</td>\n",
       "      <td>0.264306</td>\n",
       "      <td>-1.747202</td>\n",
       "      <td>-1.462740</td>\n",
       "      <td>-1.147379</td>\n",
       "      <td>0.752695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.379294</td>\n",
       "      <td>-1.636155</td>\n",
       "      <td>-1.430053</td>\n",
       "      <td>0.630301</td>\n",
       "      <td>-0.142524</td>\n",
       "      <td>1.089372</td>\n",
       "      <td>1.083219</td>\n",
       "      <td>-1.715190</td>\n",
       "      <td>-1.554196</td>\n",
       "      <td>-1.694621</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.087803</td>\n",
       "      <td>-1.303281</td>\n",
       "      <td>0.116535</td>\n",
       "      <td>0.707242</td>\n",
       "      <td>0.798143</td>\n",
       "      <td>-0.133823</td>\n",
       "      <td>-1.748160</td>\n",
       "      <td>-1.463585</td>\n",
       "      <td>-1.401313</td>\n",
       "      <td>1.455236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.908696</td>\n",
       "      <td>-1.671099</td>\n",
       "      <td>-1.611066</td>\n",
       "      <td>0.448563</td>\n",
       "      <td>-1.218104</td>\n",
       "      <td>1.052349</td>\n",
       "      <td>1.213578</td>\n",
       "      <td>-1.715072</td>\n",
       "      <td>-1.459007</td>\n",
       "      <td>-1.719276</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.763722</td>\n",
       "      <td>-0.655116</td>\n",
       "      <td>-0.695699</td>\n",
       "      <td>0.586953</td>\n",
       "      <td>0.099654</td>\n",
       "      <td>0.991306</td>\n",
       "      <td>-1.745728</td>\n",
       "      <td>-1.481762</td>\n",
       "      <td>-1.468218</td>\n",
       "      <td>0.993800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.392862</td>\n",
       "      <td>-1.670521</td>\n",
       "      <td>-1.219733</td>\n",
       "      <td>0.046698</td>\n",
       "      <td>-0.861674</td>\n",
       "      <td>0.661535</td>\n",
       "      <td>1.135326</td>\n",
       "      <td>-1.712400</td>\n",
       "      <td>-1.599550</td>\n",
       "      <td>-1.719556</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.424196</td>\n",
       "      <td>-1.246706</td>\n",
       "      <td>-0.386247</td>\n",
       "      <td>0.707216</td>\n",
       "      <td>0.873591</td>\n",
       "      <td>1.810715</td>\n",
       "      <td>-1.733457</td>\n",
       "      <td>-1.134984</td>\n",
       "      <td>-1.673585</td>\n",
       "      <td>0.206294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.403591</td>\n",
       "      <td>-1.712968</td>\n",
       "      <td>-1.476937</td>\n",
       "      <td>0.282476</td>\n",
       "      <td>-0.952883</td>\n",
       "      <td>1.081380</td>\n",
       "      <td>0.250162</td>\n",
       "      <td>-1.697196</td>\n",
       "      <td>-1.433646</td>\n",
       "      <td>-1.711076</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.512201</td>\n",
       "      <td>-1.409165</td>\n",
       "      <td>0.225623</td>\n",
       "      <td>0.659767</td>\n",
       "      <td>-0.270583</td>\n",
       "      <td>0.488124</td>\n",
       "      <td>-1.739537</td>\n",
       "      <td>-1.380277</td>\n",
       "      <td>-1.557396</td>\n",
       "      <td>1.012737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>0.881916</td>\n",
       "      <td>-1.662267</td>\n",
       "      <td>-1.500192</td>\n",
       "      <td>0.046194</td>\n",
       "      <td>-0.984068</td>\n",
       "      <td>1.051335</td>\n",
       "      <td>1.308702</td>\n",
       "      <td>-1.704325</td>\n",
       "      <td>-1.473874</td>\n",
       "      <td>-1.721303</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.521498</td>\n",
       "      <td>-1.007404</td>\n",
       "      <td>-0.879530</td>\n",
       "      <td>0.250384</td>\n",
       "      <td>0.821218</td>\n",
       "      <td>1.525253</td>\n",
       "      <td>-1.736708</td>\n",
       "      <td>-1.050555</td>\n",
       "      <td>-1.057167</td>\n",
       "      <td>0.206922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>0.674289</td>\n",
       "      <td>-1.692174</td>\n",
       "      <td>-1.542225</td>\n",
       "      <td>1.152259</td>\n",
       "      <td>-0.841977</td>\n",
       "      <td>1.320291</td>\n",
       "      <td>0.506080</td>\n",
       "      <td>-1.669426</td>\n",
       "      <td>-1.598777</td>\n",
       "      <td>-1.692820</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.947423</td>\n",
       "      <td>-1.367081</td>\n",
       "      <td>-0.877269</td>\n",
       "      <td>0.022208</td>\n",
       "      <td>0.860660</td>\n",
       "      <td>1.165986</td>\n",
       "      <td>-1.742857</td>\n",
       "      <td>-1.476454</td>\n",
       "      <td>-1.378397</td>\n",
       "      <td>1.315948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>0.546966</td>\n",
       "      <td>-1.686088</td>\n",
       "      <td>-1.386902</td>\n",
       "      <td>-0.474575</td>\n",
       "      <td>-0.745600</td>\n",
       "      <td>0.885027</td>\n",
       "      <td>1.557217</td>\n",
       "      <td>-1.653044</td>\n",
       "      <td>-1.476545</td>\n",
       "      <td>-1.727185</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.689841</td>\n",
       "      <td>-1.416341</td>\n",
       "      <td>0.129194</td>\n",
       "      <td>1.018297</td>\n",
       "      <td>1.110545</td>\n",
       "      <td>1.066289</td>\n",
       "      <td>-1.745026</td>\n",
       "      <td>-1.387244</td>\n",
       "      <td>-1.461599</td>\n",
       "      <td>1.134802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>0.583664</td>\n",
       "      <td>-1.660465</td>\n",
       "      <td>-1.564322</td>\n",
       "      <td>0.571392</td>\n",
       "      <td>-1.122003</td>\n",
       "      <td>1.088288</td>\n",
       "      <td>0.730211</td>\n",
       "      <td>-1.685058</td>\n",
       "      <td>-1.592363</td>\n",
       "      <td>-1.707006</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.003026</td>\n",
       "      <td>-1.418858</td>\n",
       "      <td>-0.260910</td>\n",
       "      <td>-0.065412</td>\n",
       "      <td>1.285587</td>\n",
       "      <td>0.488780</td>\n",
       "      <td>-1.750642</td>\n",
       "      <td>-1.579210</td>\n",
       "      <td>-1.328196</td>\n",
       "      <td>1.324674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>-0.025244</td>\n",
       "      <td>-1.672403</td>\n",
       "      <td>-1.548496</td>\n",
       "      <td>0.728325</td>\n",
       "      <td>-1.372018</td>\n",
       "      <td>1.746526</td>\n",
       "      <td>0.411782</td>\n",
       "      <td>-1.710202</td>\n",
       "      <td>-1.464592</td>\n",
       "      <td>-1.733416</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.954379</td>\n",
       "      <td>-0.793743</td>\n",
       "      <td>-0.711619</td>\n",
       "      <td>1.058451</td>\n",
       "      <td>1.775981</td>\n",
       "      <td>0.813672</td>\n",
       "      <td>-1.747427</td>\n",
       "      <td>-1.438802</td>\n",
       "      <td>-1.464731</td>\n",
       "      <td>0.319901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 190 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6    \\\n",
       "0    0.286011 -1.681617 -1.607033  0.750308 -1.291434  1.755265  0.011078   \n",
       "1    0.379294 -1.636155 -1.430053  0.630301 -0.142524  1.089372  1.083219   \n",
       "2    0.908696 -1.671099 -1.611066  0.448563 -1.218104  1.052349  1.213578   \n",
       "3   -0.392862 -1.670521 -1.219733  0.046698 -0.861674  0.661535  1.135326   \n",
       "4    0.403591 -1.712968 -1.476937  0.282476 -0.952883  1.081380  0.250162   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "295  0.881916 -1.662267 -1.500192  0.046194 -0.984068  1.051335  1.308702   \n",
       "296  0.674289 -1.692174 -1.542225  1.152259 -0.841977  1.320291  0.506080   \n",
       "297  0.546966 -1.686088 -1.386902 -0.474575 -0.745600  0.885027  1.557217   \n",
       "298  0.583664 -1.660465 -1.564322  0.571392 -1.122003  1.088288  0.730211   \n",
       "299 -0.025244 -1.672403 -1.548496  0.728325 -1.372018  1.746526  0.411782   \n",
       "\n",
       "          7         8         9    ...       180       181       182  \\\n",
       "0   -1.658436 -1.562615 -1.720451  ... -0.557999 -1.172544 -0.967577   \n",
       "1   -1.715190 -1.554196 -1.694621  ... -1.087803 -1.303281  0.116535   \n",
       "2   -1.715072 -1.459007 -1.719276  ... -0.763722 -0.655116 -0.695699   \n",
       "3   -1.712400 -1.599550 -1.719556  ... -0.424196 -1.246706 -0.386247   \n",
       "4   -1.697196 -1.433646 -1.711076  ... -0.512201 -1.409165  0.225623   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "295 -1.704325 -1.473874 -1.721303  ... -0.521498 -1.007404 -0.879530   \n",
       "296 -1.669426 -1.598777 -1.692820  ... -0.947423 -1.367081 -0.877269   \n",
       "297 -1.653044 -1.476545 -1.727185  ... -0.689841 -1.416341  0.129194   \n",
       "298 -1.685058 -1.592363 -1.707006  ... -1.003026 -1.418858 -0.260910   \n",
       "299 -1.710202 -1.464592 -1.733416  ... -0.954379 -0.793743 -0.711619   \n",
       "\n",
       "          183       184       185       186       187       188       189  \n",
       "0    0.428967  0.268811  0.264306 -1.747202 -1.462740 -1.147379  0.752695  \n",
       "1    0.707242  0.798143 -0.133823 -1.748160 -1.463585 -1.401313  1.455236  \n",
       "2    0.586953  0.099654  0.991306 -1.745728 -1.481762 -1.468218  0.993800  \n",
       "3    0.707216  0.873591  1.810715 -1.733457 -1.134984 -1.673585  0.206294  \n",
       "4    0.659767 -0.270583  0.488124 -1.739537 -1.380277 -1.557396  1.012737  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "295  0.250384  0.821218  1.525253 -1.736708 -1.050555 -1.057167  0.206922  \n",
       "296  0.022208  0.860660  1.165986 -1.742857 -1.476454 -1.378397  1.315948  \n",
       "297  1.018297  1.110545  1.066289 -1.745026 -1.387244 -1.461599  1.134802  \n",
       "298 -0.065412  1.285587  0.488780 -1.750642 -1.579210 -1.328196  1.324674  \n",
       "299  1.058451  1.775981  0.813672 -1.747427 -1.438802 -1.464731  0.319901  \n",
       "\n",
       "[300 rows x 190 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ae_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0      True\n",
       " 1      True\n",
       " 2      True\n",
       " 3      True\n",
       " 4      True\n",
       "       ...  \n",
       " 95    False\n",
       " 96    False\n",
       " 97    False\n",
       " 98    False\n",
       " 99    False\n",
       " Name: train_status, Length: 400, dtype: bool]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ae_x = df_ae.loc[df_ae['train_status'] =='train']\n",
    "train_ae_x.drop(columns = ['train_status'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_reduce(x_train, x_valid):\n",
    "        pca = PCA(n_components=57)\n",
    "        x_pca_train = pca.fit_transform(x_train)\n",
    "        x_pca_valid = pca.transform(x_valid)\n",
    "        x_pca_train = pd.DataFrame(x_pca_train)\n",
    "        x_pca_valid = pd.DataFrame(x_pca_valid)\n",
    "        x_pca_train['train_status'] = 'train' \n",
    "        x_pca_valid['train_status'] = 'test'\n",
    "        df_pca = pd.concat([x_pca_train, x_pca_valid], axis = 0)\n",
    "        return df_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>train_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.471503</td>\n",
       "      <td>-0.938684</td>\n",
       "      <td>0.722844</td>\n",
       "      <td>-1.080448</td>\n",
       "      <td>-0.550212</td>\n",
       "      <td>-0.456904</td>\n",
       "      <td>-0.594158</td>\n",
       "      <td>0.299010</td>\n",
       "      <td>-0.345354</td>\n",
       "      <td>-0.259012</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.545007</td>\n",
       "      <td>-0.893105</td>\n",
       "      <td>0.532089</td>\n",
       "      <td>0.522779</td>\n",
       "      <td>-0.052114</td>\n",
       "      <td>-0.028399</td>\n",
       "      <td>-0.059819</td>\n",
       "      <td>-0.057401</td>\n",
       "      <td>-0.657473</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.597896</td>\n",
       "      <td>0.749902</td>\n",
       "      <td>-0.545454</td>\n",
       "      <td>-2.120778</td>\n",
       "      <td>0.061519</td>\n",
       "      <td>-0.388359</td>\n",
       "      <td>0.616536</td>\n",
       "      <td>0.116393</td>\n",
       "      <td>-0.117526</td>\n",
       "      <td>-0.922683</td>\n",
       "      <td>...</td>\n",
       "      <td>0.327284</td>\n",
       "      <td>-0.074456</td>\n",
       "      <td>0.650318</td>\n",
       "      <td>-0.026963</td>\n",
       "      <td>0.519379</td>\n",
       "      <td>0.172174</td>\n",
       "      <td>0.193085</td>\n",
       "      <td>-0.282714</td>\n",
       "      <td>-0.995653</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.661038</td>\n",
       "      <td>0.402187</td>\n",
       "      <td>-0.044178</td>\n",
       "      <td>-0.678541</td>\n",
       "      <td>-0.215063</td>\n",
       "      <td>-0.526773</td>\n",
       "      <td>-0.060653</td>\n",
       "      <td>0.985703</td>\n",
       "      <td>-0.430016</td>\n",
       "      <td>-0.696795</td>\n",
       "      <td>...</td>\n",
       "      <td>0.690787</td>\n",
       "      <td>-0.034156</td>\n",
       "      <td>-0.475457</td>\n",
       "      <td>-0.791914</td>\n",
       "      <td>0.400384</td>\n",
       "      <td>0.595436</td>\n",
       "      <td>-0.051831</td>\n",
       "      <td>-0.457005</td>\n",
       "      <td>-0.679141</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.520373</td>\n",
       "      <td>-0.526457</td>\n",
       "      <td>0.834462</td>\n",
       "      <td>2.881337</td>\n",
       "      <td>-1.429538</td>\n",
       "      <td>1.487006</td>\n",
       "      <td>-0.232425</td>\n",
       "      <td>0.340083</td>\n",
       "      <td>0.237961</td>\n",
       "      <td>-0.114992</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.094980</td>\n",
       "      <td>-0.318086</td>\n",
       "      <td>0.226651</td>\n",
       "      <td>0.078899</td>\n",
       "      <td>-0.500580</td>\n",
       "      <td>-0.383087</td>\n",
       "      <td>-0.585835</td>\n",
       "      <td>0.790962</td>\n",
       "      <td>-0.124492</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.255171</td>\n",
       "      <td>0.281806</td>\n",
       "      <td>0.305122</td>\n",
       "      <td>0.278138</td>\n",
       "      <td>0.877982</td>\n",
       "      <td>0.599567</td>\n",
       "      <td>-1.711069</td>\n",
       "      <td>0.710685</td>\n",
       "      <td>-0.092102</td>\n",
       "      <td>-0.224902</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.677101</td>\n",
       "      <td>0.341953</td>\n",
       "      <td>0.489739</td>\n",
       "      <td>0.256139</td>\n",
       "      <td>1.013076</td>\n",
       "      <td>-0.023266</td>\n",
       "      <td>0.132844</td>\n",
       "      <td>0.097535</td>\n",
       "      <td>0.356303</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.250600</td>\n",
       "      <td>0.519219</td>\n",
       "      <td>1.023173</td>\n",
       "      <td>0.915650</td>\n",
       "      <td>1.006372</td>\n",
       "      <td>0.617418</td>\n",
       "      <td>-0.088070</td>\n",
       "      <td>-0.300852</td>\n",
       "      <td>0.157686</td>\n",
       "      <td>0.642070</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232269</td>\n",
       "      <td>-0.112554</td>\n",
       "      <td>0.062340</td>\n",
       "      <td>0.333561</td>\n",
       "      <td>-0.100245</td>\n",
       "      <td>0.087601</td>\n",
       "      <td>-0.401799</td>\n",
       "      <td>0.047381</td>\n",
       "      <td>0.417175</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1.267989</td>\n",
       "      <td>-0.913610</td>\n",
       "      <td>0.256582</td>\n",
       "      <td>-0.345304</td>\n",
       "      <td>-1.081689</td>\n",
       "      <td>0.917660</td>\n",
       "      <td>0.181186</td>\n",
       "      <td>-0.575468</td>\n",
       "      <td>0.276676</td>\n",
       "      <td>0.031298</td>\n",
       "      <td>...</td>\n",
       "      <td>0.128917</td>\n",
       "      <td>-0.497415</td>\n",
       "      <td>-1.057189</td>\n",
       "      <td>0.884635</td>\n",
       "      <td>0.099020</td>\n",
       "      <td>0.289597</td>\n",
       "      <td>0.149911</td>\n",
       "      <td>0.058205</td>\n",
       "      <td>-0.782336</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>-0.038408</td>\n",
       "      <td>0.269255</td>\n",
       "      <td>0.966371</td>\n",
       "      <td>-0.778252</td>\n",
       "      <td>0.730750</td>\n",
       "      <td>-0.204290</td>\n",
       "      <td>0.505082</td>\n",
       "      <td>-1.373290</td>\n",
       "      <td>0.878629</td>\n",
       "      <td>0.333496</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.185657</td>\n",
       "      <td>-0.811218</td>\n",
       "      <td>0.012346</td>\n",
       "      <td>0.095360</td>\n",
       "      <td>0.174385</td>\n",
       "      <td>-0.156357</td>\n",
       "      <td>-0.189497</td>\n",
       "      <td>-0.042771</td>\n",
       "      <td>-1.077269</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>-0.073523</td>\n",
       "      <td>0.212095</td>\n",
       "      <td>0.826139</td>\n",
       "      <td>0.077370</td>\n",
       "      <td>-0.960395</td>\n",
       "      <td>0.301680</td>\n",
       "      <td>-0.671235</td>\n",
       "      <td>-0.432688</td>\n",
       "      <td>0.755138</td>\n",
       "      <td>0.426795</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046492</td>\n",
       "      <td>-0.222965</td>\n",
       "      <td>0.387004</td>\n",
       "      <td>0.450156</td>\n",
       "      <td>0.016386</td>\n",
       "      <td>-0.320359</td>\n",
       "      <td>0.592497</td>\n",
       "      <td>0.631707</td>\n",
       "      <td>-1.317769</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>-1.877034</td>\n",
       "      <td>0.119229</td>\n",
       "      <td>0.038170</td>\n",
       "      <td>0.389429</td>\n",
       "      <td>-0.738118</td>\n",
       "      <td>-0.888248</td>\n",
       "      <td>1.093840</td>\n",
       "      <td>0.141660</td>\n",
       "      <td>0.447398</td>\n",
       "      <td>-0.707813</td>\n",
       "      <td>...</td>\n",
       "      <td>0.101897</td>\n",
       "      <td>-0.036665</td>\n",
       "      <td>-0.563530</td>\n",
       "      <td>-0.713930</td>\n",
       "      <td>-0.059573</td>\n",
       "      <td>0.590022</td>\n",
       "      <td>0.047072</td>\n",
       "      <td>0.167958</td>\n",
       "      <td>0.000909</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6  \\\n",
       "0  -1.471503 -0.938684  0.722844 -1.080448 -0.550212 -0.456904 -0.594158   \n",
       "1   0.597896  0.749902 -0.545454 -2.120778  0.061519 -0.388359  0.616536   \n",
       "2   1.661038  0.402187 -0.044178 -0.678541 -0.215063 -0.526773 -0.060653   \n",
       "3   2.520373 -0.526457  0.834462  2.881337 -1.429538  1.487006 -0.232425   \n",
       "4  -1.255171  0.281806  0.305122  0.278138  0.877982  0.599567 -1.711069   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "95  0.250600  0.519219  1.023173  0.915650  1.006372  0.617418 -0.088070   \n",
       "96  1.267989 -0.913610  0.256582 -0.345304 -1.081689  0.917660  0.181186   \n",
       "97 -0.038408  0.269255  0.966371 -0.778252  0.730750 -0.204290  0.505082   \n",
       "98 -0.073523  0.212095  0.826139  0.077370 -0.960395  0.301680 -0.671235   \n",
       "99 -1.877034  0.119229  0.038170  0.389429 -0.738118 -0.888248  1.093840   \n",
       "\n",
       "           7         8         9  ...        48        49        50        51  \\\n",
       "0   0.299010 -0.345354 -0.259012  ... -0.545007 -0.893105  0.532089  0.522779   \n",
       "1   0.116393 -0.117526 -0.922683  ...  0.327284 -0.074456  0.650318 -0.026963   \n",
       "2   0.985703 -0.430016 -0.696795  ...  0.690787 -0.034156 -0.475457 -0.791914   \n",
       "3   0.340083  0.237961 -0.114992  ... -0.094980 -0.318086  0.226651  0.078899   \n",
       "4   0.710685 -0.092102 -0.224902  ... -0.677101  0.341953  0.489739  0.256139   \n",
       "..       ...       ...       ...  ...       ...       ...       ...       ...   \n",
       "95 -0.300852  0.157686  0.642070  ...  0.232269 -0.112554  0.062340  0.333561   \n",
       "96 -0.575468  0.276676  0.031298  ...  0.128917 -0.497415 -1.057189  0.884635   \n",
       "97 -1.373290  0.878629  0.333496  ... -0.185657 -0.811218  0.012346  0.095360   \n",
       "98 -0.432688  0.755138  0.426795  ...  0.046492 -0.222965  0.387004  0.450156   \n",
       "99  0.141660  0.447398 -0.707813  ...  0.101897 -0.036665 -0.563530 -0.713930   \n",
       "\n",
       "          52        53        54        55        56  train_status  \n",
       "0  -0.052114 -0.028399 -0.059819 -0.057401 -0.657473         train  \n",
       "1   0.519379  0.172174  0.193085 -0.282714 -0.995653         train  \n",
       "2   0.400384  0.595436 -0.051831 -0.457005 -0.679141         train  \n",
       "3  -0.500580 -0.383087 -0.585835  0.790962 -0.124492         train  \n",
       "4   1.013076 -0.023266  0.132844  0.097535  0.356303         train  \n",
       "..       ...       ...       ...       ...       ...           ...  \n",
       "95 -0.100245  0.087601 -0.401799  0.047381  0.417175          test  \n",
       "96  0.099020  0.289597  0.149911  0.058205 -0.782336          test  \n",
       "97  0.174385 -0.156357 -0.189497 -0.042771 -1.077269          test  \n",
       "98  0.016386 -0.320359  0.592497  0.631707 -1.317769          test  \n",
       "99 -0.059573  0.590022  0.047072  0.167958  0.000909          test  \n",
       "\n",
       "[400 rows x 58 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pca = pca_reduce(x_train, x_valid)\n",
    "df_pca\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "def logit_mod(df):\n",
    "    train_encoded = df.loc[df['train_status'] =='train']\n",
    "    train_encoded.drop(columns = ['train_status'], inplace = True)\n",
    "    test_encoded = df.loc[df['train_status'] =='test']\n",
    "    test_encoded.drop(columns = ['train_status'], inplace = True)\n",
    "    model_logit = LogisticRegression(solver='liblinear', random_state=0).fit(train_encoded,y_train)\n",
    "    print('classification_report:',classification_report(model_logit.predict(train_encoded),y_train))\n",
    "    print('classification_report:',classification_report(model_logit.predict(test_encoded),y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98        68\n",
      "           1       1.00      0.99      0.99       232\n",
      "\n",
      "    accuracy                           0.99       300\n",
      "   macro avg       0.98      0.99      0.99       300\n",
      "weighted avg       0.99      0.99      0.99       300\n",
      "\n",
      "classification_report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.92      0.88        24\n",
      "           1       0.97      0.95      0.96        76\n",
      "\n",
      "    accuracy                           0.94       100\n",
      "   macro avg       0.91      0.93      0.92       100\n",
      "weighted avg       0.94      0.94      0.94       100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nahomw\\AppData\\Local\\Temp\\ipykernel_27772\\1884567426.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_encoded.drop(columns = ['train_status'], inplace = True)\n",
      "C:\\Users\\nahomw\\AppData\\Local\\Temp\\ipykernel_27772\\1884567426.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_encoded.drop(columns = ['train_status'], inplace = True)\n",
      "c:\\Users\\nahomw\\Anaconda3\\envs\\alzhymer\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "logit_mod(df_ae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95        21\n",
      "           1       1.00      0.97      0.98        59\n",
      "\n",
      "    accuracy                           0.97        80\n",
      "   macro avg       0.96      0.98      0.97        80\n",
      "weighted avg       0.98      0.97      0.98        80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('classification_report:',classification_report(xgb_unbalanced.predict(x_pca_valid),y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nahomw\\Anaconda3\\envs\\alzhymer\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model_logit = LogisticRegression(solver='liblinear', random_state=0).fit(x_pca_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99        74\n",
      "           1       1.00      1.00      1.00       246\n",
      "\n",
      "    accuracy                           1.00       320\n",
      "   macro avg       1.00      0.99      1.00       320\n",
      "weighted avg       1.00      1.00      1.00       320\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('classification_report:',classification_report(y_train, model_logit.predict(x_pca_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91        23\n",
      "           1       0.96      0.96      0.96        57\n",
      "\n",
      "    accuracy                           0.95        80\n",
      "   macro avg       0.94      0.94      0.94        80\n",
      "weighted avg       0.95      0.95      0.95        80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('classification_report:',classification_report(y_valid, model_logit.predict(x_pca_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.91      0.95        23\n",
      "           1       0.97      1.00      0.98        57\n",
      "\n",
      "    accuracy                           0.97        80\n",
      "   macro avg       0.98      0.96      0.97        80\n",
      "weighted avg       0.98      0.97      0.97        80\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nahomw\\Anaconda3\\envs\\alzhymer\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "pca_svc = svm.SVC()\n",
    "pca_svc.fit(x_pca_train, y_train)\n",
    "print('classification_report:',classification_report(y_valid, pca_svc.predict(x_pca_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGboost Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid-search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "estimator = XGBClassifier(\n",
    "    objective= 'binary:logistic',\n",
    "    nthread=4,\n",
    "    seed=42\n",
    ")\n",
    "parameters = {\n",
    "    'max_depth': range (2, 7, 1),\n",
    "    'n_estimators': range(60, 220, 40),\n",
    "    'learning_rate': [0.1, 0.05, 0.01, 0.001]\n",
    "    # 'alpha':[0.01,0.1,1,10]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(\n",
    "    estimator=estimator,\n",
    "    param_grid=parameters,\n",
    "    scoring = 'roc_auc',\n",
    "    n_jobs = 10,\n",
    "    cv = 10,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 80 candidates, totalling 800 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     gpu_id=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None...\n",
       "                                     max_cat_to_onehot=None,\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None, nthread=4,\n",
       "                                     num_parallel_tree=None, predictor=None, ...),\n",
       "             n_jobs=10,\n",
       "             param_grid={'learning_rate': [0.1, 0.05, 0.01, 0.001],\n",
       "                         'max_depth': range(2, 7),\n",
       "                         'n_estimators': range(60, 220, 40)},\n",
       "             scoring='roc_auc', verbose=True)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(train_encoded,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=180, n_jobs=None, nthread=4, num_parallel_tree=None,\n",
       "              predictor=None, ...)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(alpha=1, base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=2, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, ...)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_unbalanced = XGBClassifier(n_estimators=100,max_depth=2, learning_rate=0.05, alpha=1)\n",
    "xgb_unbalanced.fit(train_encoded,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.85      0.92        71\n",
      "           1       0.95      1.00      0.98       229\n",
      "\n",
      "    accuracy                           0.96       300\n",
      "   macro avg       0.98      0.92      0.95       300\n",
      "weighted avg       0.97      0.96      0.96       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('classification_report:',classification_report(y_train, xgb_unbalanced.predict(train_encoded)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.77      0.87        26\n",
      "           1       0.93      1.00      0.96        74\n",
      "\n",
      "    accuracy                           0.94       100\n",
      "   macro avg       0.96      0.88      0.92       100\n",
      "weighted avg       0.94      0.94      0.94       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('classification_report:',classification_report(y_valid, xgb_unbalanced.predict(test_encoded)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xgb_unbalanced.fit(train_encoded,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 128 candidates, totalling 1280 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_valid\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nahomw\\Anaconda3\\envs\\alzhymer\\lib\\site-packages\\sklearn\\utils\\validation.py:63\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m extra_args \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(args) \u001b[39m-\u001b[39m \u001b[39mlen\u001b[39m(all_args)\n\u001b[0;32m     62\u001b[0m \u001b[39mif\u001b[39;00m extra_args \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m---> 63\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[39m# extra_args > 0\u001b[39;00m\n\u001b[0;32m     66\u001b[0m args_msg \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(name, arg)\n\u001b[0;32m     67\u001b[0m             \u001b[39mfor\u001b[39;00m name, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(kwonly_args[:extra_args],\n\u001b[0;32m     68\u001b[0m                                  args[\u001b[39m-\u001b[39mextra_args:])]\n",
      "File \u001b[1;32mc:\\Users\\nahomw\\Anaconda3\\envs\\alzhymer\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    835\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    836\u001b[0m         all_candidate_params, n_splits, all_out,\n\u001b[0;32m    837\u001b[0m         all_more_results)\n\u001b[0;32m    839\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 841\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    843\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    844\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    845\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\nahomw\\Anaconda3\\envs\\alzhymer\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1296\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1294\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1295\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1296\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[1;32mc:\\Users\\nahomw\\Anaconda3\\envs\\alzhymer\\lib\\site-packages\\sklearn\\model_selection\\_search.py:795\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    790\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    791\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    792\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    793\u001b[0m               n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits))\n\u001b[1;32m--> 795\u001b[0m out \u001b[39m=\u001b[39m parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0;32m    796\u001b[0m                                        X, y,\n\u001b[0;32m    797\u001b[0m                                        train\u001b[39m=\u001b[39;49mtrain, test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    798\u001b[0m                                        parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    799\u001b[0m                                        split_progress\u001b[39m=\u001b[39;49m(\n\u001b[0;32m    800\u001b[0m                                            split_idx,\n\u001b[0;32m    801\u001b[0m                                            n_splits),\n\u001b[0;32m    802\u001b[0m                                        candidate_progress\u001b[39m=\u001b[39;49m(\n\u001b[0;32m    803\u001b[0m                                            cand_idx,\n\u001b[0;32m    804\u001b[0m                                            n_candidates),\n\u001b[0;32m    805\u001b[0m                                        \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs)\n\u001b[0;32m    806\u001b[0m                \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters),\n\u001b[0;32m    807\u001b[0m                    (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    808\u001b[0m                    \u001b[39menumerate\u001b[39;49m(candidate_params),\n\u001b[0;32m    809\u001b[0m                    \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))))\n\u001b[0;32m    811\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    812\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    813\u001b[0m                      \u001b[39m'\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    814\u001b[0m                      \u001b[39m'\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\nahomw\\Anaconda3\\envs\\alzhymer\\lib\\site-packages\\joblib\\parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1098\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[0;32m   1099\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[1;32mc:\\Users\\nahomw\\Anaconda3\\envs\\alzhymer\\lib\\site-packages\\joblib\\parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    974\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m--> 975\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[0;32m    976\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[1;32mc:\\Users\\nahomw\\Anaconda3\\envs\\alzhymer\\lib\\site-packages\\joblib\\_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 567\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m    568\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    569\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nahomw\\Anaconda3\\envs\\alzhymer\\lib\\concurrent\\futures\\_base.py:439\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    436\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m    437\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[1;32m--> 439\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[0;32m    441\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    442\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32mc:\\Users\\nahomw\\Anaconda3\\envs\\alzhymer\\lib\\threading.py:302\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    300\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    301\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 302\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[0;32m    303\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    304\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "grid_search.fit(x_valid,y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=2, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=60, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_raw = XGBClassifier( n_estimators=60,max_depth=2, learning_rate=0.1)\n",
    "xgb_raw.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99        74\n",
      "           1       1.00      1.00      1.00       246\n",
      "\n",
      "    accuracy                           1.00       320\n",
      "   macro avg       1.00      0.99      1.00       320\n",
      "weighted avg       1.00      1.00      1.00       320\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('classification_report:',classification_report(y_train, xgb_raw.predict(x_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.57      0.72        23\n",
      "           1       0.85      1.00      0.92        57\n",
      "\n",
      "    accuracy                           0.88        80\n",
      "   macro avg       0.93      0.78      0.82        80\n",
      "weighted avg       0.89      0.88      0.86        80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('classification_report:',classification_report(y_valid, xgb_raw.predict(x_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nahomw\\AppData\\Local\\Temp\\ipykernel_26636\\3946408733.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rf_mod.fit(x_train,y_train)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_mod = RandomForestClassifier()\n",
    "rf_mod.fit(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        71\n",
      "           1       1.00      1.00      1.00       229\n",
      "\n",
      "    accuracy                           1.00       300\n",
      "   macro avg       1.00      1.00      1.00       300\n",
      "weighted avg       1.00      1.00      1.00       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('classification_report:',classification_report(y_train, rf_mod.predict(x_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 360 features, but DecisionTreeClassifier is expecting 190 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassification_report:\u001b[39m\u001b[38;5;124m'\u001b[39m,classification_report(y_valid, \u001b[43mrf_mod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_valid\u001b[49m\u001b[43m)\u001b[49m))\n",
      "File \u001b[1;32mc:\\Users\\nahomw\\Anaconda3\\envs\\alzhymer\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:630\u001b[0m, in \u001b[0;36mForestClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m    610\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    611\u001b[0m \u001b[39m    Predict class for X.\u001b[39;00m\n\u001b[0;32m    612\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[39m        The predicted classes.\u001b[39;00m\n\u001b[0;32m    629\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m     proba \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict_proba(X)\n\u001b[0;32m    632\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    633\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_\u001b[39m.\u001b[39mtake(np\u001b[39m.\u001b[39margmax(proba, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m), axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\nahomw\\Anaconda3\\envs\\alzhymer\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:674\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    672\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m    673\u001b[0m \u001b[39m# Check data\u001b[39;00m\n\u001b[1;32m--> 674\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_X_predict(X)\n\u001b[0;32m    676\u001b[0m \u001b[39m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[0;32m    677\u001b[0m n_jobs, _, _ \u001b[39m=\u001b[39m _partition_estimators(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_estimators, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs)\n",
      "File \u001b[1;32mc:\\Users\\nahomw\\Anaconda3\\envs\\alzhymer\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:422\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    418\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[39mValidate X whenever one tries to predict, apply, predict_proba.\"\"\"\u001b[39;00m\n\u001b[0;32m    420\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m--> 422\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mestimators_[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49m_validate_X_predict(X, check_input\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\nahomw\\Anaconda3\\envs\\alzhymer\\lib\\site-packages\\sklearn\\tree\\_classes.py:407\u001b[0m, in \u001b[0;36mBaseDecisionTree._validate_X_predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    405\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Validate the training data on predict (probabilities).\"\"\"\u001b[39;00m\n\u001b[0;32m    406\u001b[0m \u001b[39mif\u001b[39;00m check_input:\n\u001b[1;32m--> 407\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, dtype\u001b[39m=\u001b[39;49mDTYPE, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    408\u001b[0m                             reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    409\u001b[0m     \u001b[39mif\u001b[39;00m issparse(X) \u001b[39mand\u001b[39;00m (X\u001b[39m.\u001b[39mindices\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mintc \u001b[39mor\u001b[39;00m\n\u001b[0;32m    410\u001b[0m                         X\u001b[39m.\u001b[39mindptr\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mintc):\n\u001b[0;32m    411\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo support for np.int64 index based \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    412\u001b[0m                          \u001b[39m\"\u001b[39m\u001b[39msparse matrices\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\nahomw\\Anaconda3\\envs\\alzhymer\\lib\\site-packages\\sklearn\\base.py:437\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    434\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    436\u001b[0m \u001b[39mif\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m--> 437\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_n_features(X, reset\u001b[39m=\u001b[39;49mreset)\n\u001b[0;32m    439\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\nahomw\\Anaconda3\\envs\\alzhymer\\lib\\site-packages\\sklearn\\base.py:365\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    362\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    364\u001b[0m \u001b[39mif\u001b[39;00m n_features \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 365\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    366\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX has \u001b[39m\u001b[39m{\u001b[39;00mn_features\u001b[39m}\u001b[39;00m\u001b[39m features, but \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    367\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mis expecting \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_\u001b[39m}\u001b[39;00m\u001b[39m features as input.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: X has 360 features, but DecisionTreeClassifier is expecting 190 features as input."
     ]
    }
   ],
   "source": [
    "print('classification_report:',classification_report(y_valid, rf_mod.predict(x_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nahomw\\AppData\\Local\\Temp\\ipykernel_26636\\779682960.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rf_mod.fit(x_train,y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.35      0.51        26\n",
      "           1       0.81      1.00      0.90        74\n",
      "\n",
      "    accuracy                           0.83       100\n",
      "   macro avg       0.91      0.67      0.71       100\n",
      "weighted avg       0.86      0.83      0.80       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_mod.fit(x_train,y_train)\n",
    "print('classification_report:',classification_report(y_valid, rf_mod.predict(x_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nahomw\\AppData\\Local\\Temp\\ipykernel_26636\\1162444599.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rf_mod_red.fit(train_encoded,y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.50      0.67        26\n",
      "           1       0.85      1.00      0.92        74\n",
      "\n",
      "    accuracy                           0.87       100\n",
      "   macro avg       0.93      0.75      0.79       100\n",
      "weighted avg       0.89      0.87      0.85       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_mod_red = RandomForestClassifier()\n",
    "rf_mod_red.fit(train_encoded,y_train)\n",
    "print('classification_report:',classification_report(y_valid, rf_mod_red.predict(test_encoded)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[144], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassification_report:\u001b[39m\u001b[38;5;124m'\u001b[39m,classification_report(\u001b[43my_test\u001b[49m, rf_mod_red\u001b[38;5;241m.\u001b[39mpredict(test_encoded)))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "print('classification_report:',classification_report(y_test, rf_mod_red.predict(test_encoded)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 4ms/step\n",
      "Accuracy: 0.03624933359362187\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:',mean_squared_error(stacked_ae.predict(x_train), x_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nahomw\\Anaconda3\\envs\\alzhymer\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model_logit = LogisticRegression(solver='liblinear', random_state=0).fit(train_encoded, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.87      0.89        23\n",
      "           1       0.95      0.96      0.96        57\n",
      "\n",
      "    accuracy                           0.94        80\n",
      "   macro avg       0.93      0.92      0.92        80\n",
      "weighted avg       0.94      0.94      0.94        80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model.predict(test_encoded, y_valid)\n",
    "print('classification_report:',classification_report(y_valid, model_logit.predict(test_encoded)))\n",
    "# print('classification_report:',classification_report(y_train, model_logit.predict(train_encoded)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m model_lda \u001b[38;5;241m=\u001b[39m LinearDiscriminantAnalysis()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# model_qda.fit(train_encoded, y_train)\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m model_lda\u001b[38;5;241m.\u001b[39mfit(\u001b[43mx_train\u001b[49m, y_train)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassification_report:\u001b[39m\u001b[38;5;124m'\u001b[39m,classification_report(y_valid, model_lda\u001b[38;5;241m.\u001b[39mpredict(x_valid)))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "model_qda = QuadraticDiscriminantAnalysis()\n",
    "model_lda = LinearDiscriminantAnalysis()\n",
    "# model_qda.fit(train_encoded, y_train)\n",
    "model_lda.fit(x_train, y_train)\n",
    "print('classification_report:',classification_report(y_valid, model_lda.predict(x_valid)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC (linear and quadratic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.91      0.95        23\n",
      "           1       0.97      1.00      0.98        57\n",
      "\n",
      "    accuracy                           0.97        80\n",
      "   macro avg       0.98      0.96      0.97        80\n",
      "weighted avg       0.98      0.97      0.97        80\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nahomw\\Anaconda3\\envs\\alzhymer\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "model_svc = svm.SVC()\n",
    "model_svc.fit(train_encoded, y_train)\n",
    "print('classification_report:',classification_report(y_valid, model_svc.predict(test_encoded)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.73      0.84        74\n",
      "           1       0.92      1.00      0.96       246\n",
      "\n",
      "    accuracy                           0.93       320\n",
      "   macro avg       0.95      0.86      0.90       320\n",
      "weighted avg       0.94      0.93      0.93       320\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('classification_report:',classification_report(y_train, model_svc.predict(train_encoded)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        74\n",
      "           1       0.77      1.00      0.87       246\n",
      "\n",
      "    accuracy                           0.77       320\n",
      "   macro avg       0.38      0.50      0.43       320\n",
      "weighted avg       0.59      0.77      0.67       320\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nahomw\\Anaconda3\\envs\\alzhymer\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "c:\\Users\\nahomw\\Anaconda3\\envs\\alzhymer\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\nahomw\\Anaconda3\\envs\\alzhymer\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\nahomw\\Anaconda3\\envs\\alzhymer\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model_svc.fit(train_encoded, y_train)\n",
    "print('classification_report:',classification_report(y_train, model_svc.predict(train_encoded)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(400, 190)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_2_encoded = encoder.predict(x_test)\n",
    "test_2_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 190)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_2_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_2_encoded = encoder.predict(x_test)\n",
    "to_file = xgb_unbalanced.predict(test_2_encoded)\n",
    "# to_file_svm = model_svc.predict(test_2_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     prediction\n",
       "0             1\n",
       "1             1\n",
       "2             1\n",
       "3             0\n",
       "4             1\n",
       "..          ...\n",
       "395           1\n",
       "396           1\n",
       "397           1\n",
       "398           1\n",
       "399           1\n",
       "\n",
       "[400 rows x 1 columns]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final = pd.DataFrame(to_file)\n",
    "df_final.columns = ['prediction']\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prev = pd.read_csv(\"test_alz_pred.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_final['prediction'].replace({0:'C',1:'AD'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(  prediction\n",
       " 0          C\n",
       " 1         AD\n",
       " 2          C\n",
       " 3          C\n",
       " 4         AD,\n",
       "   prediction\n",
       " 0         AD\n",
       " 1         AD\n",
       " 2         AD\n",
       " 3          C\n",
       " 4         AD)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prev.head(), df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, accuracy_score, confusion_matrix\n",
    "accuracy_score(df_final, df_prev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prediction\n",
       "AD            333\n",
       "C              67\n",
       "dtype: int64"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(alpha=1, base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=2, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, ...)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_unbalanced = XGBClassifier(n_estimators=100,max_depth=2, learning_rate=0.05, alpha=1)\n",
    "xgb_unbalanced.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nahomw\\AppData\\Local\\Temp\\ipykernel_26636\\3150718206.py:3: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_test_encoded = train_encoded.append(test_encoded)\n"
     ]
    }
   ],
   "source": [
    "train_encoded = pd.DataFrame(train_encoded)\n",
    "test_encoded = pd.DataFrame(test_encoded)\n",
    "train_test_encoded = train_encoded.append(test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 190)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nahomw\\AppData\\Local\\Temp\\ipykernel_26636\\2982698167.py:3: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_test_y = y_train.append(y_valid)\n"
     ]
    }
   ],
   "source": [
    "y_train = pd.DataFrame(y_train)\n",
    "y_valid = pd.DataFrame(y_valid)\n",
    "train_test_y = y_train.append(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((400, 190), (400, 1))"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_encoded.shape, train_test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(alpha=1, base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=2, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, ...)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_unbalanced = XGBClassifier(n_estimators=100,max_depth=2, learning_rate=0.05, alpha=1)\n",
    "xgb_unbalanced.fit(train_test_encoded,train_test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "test_2_encoded = encoder.predict(x_test)\n",
    "to_file = xgb_unbalanced.predict(test_2_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1,\n",
       "       0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1,\n",
       "       1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_prev = pd.DataFrame(to_file)\n",
    "df_prev.replace({0:'C',1:'AD'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, accuracy_score, confusion_matrix\n",
    "accuracy_score(df_final, df_prev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prev.to_csv('test_alz_pred_1.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prediction\n",
       "AD            313\n",
       "C              87\n",
       "dtype: int64"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    325\n",
       "0     75\n",
       "dtype: int64"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(to_file).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('alzhymer')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3f1032128968871d824ee9c779ab00a79d70df1ba9e588c74f3e40dbe0492ce7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
